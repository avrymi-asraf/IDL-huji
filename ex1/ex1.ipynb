{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/avrymi-asraf/IDL-huji/blob/main/ex1/ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import plotly.express as px"
   ],
   "metadata": {
    "id": "ViXcSiABL3A9",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.760023Z",
     "start_time": "2024-05-22T08:05:28.370526Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# for clab\n",
    "# !git clone https://github.com/avrymi-asraf/IDL-huji.git\n",
    "# !mv /content/IDL-huji/ex1/ex1_data* ."
   ],
   "metadata": {
    "id": "NSb7IqrvNSL6",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.779557Z",
     "start_time": "2024-05-22T08:05:30.761680Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# make data into 180 vector\n",
    "def load_raw(folder_path ='C:\\\\Users\\H\\PycharmProjects\\IDL-huji\\ex1\\ex1_data\\\\'):\n",
    "    raw_neg_data = open(folder_path+'neg_A0201.txt', 'r').read().split('\\n')\n",
    "    raw_pos_data = open(folder_path+'pos_A0201.txt', 'r').read().split('\\n')\n",
    "    return raw_neg_data, raw_pos_data\n",
    "# raw_neg_data , raw_pos_data = load_raw()\n",
    "raw_neg_data , raw_pos_data = load_raw('ex1_data/')\n",
    "\n",
    "amino_to_ind = {i:c for c,i in enumerate(set(\"\".join(raw_neg_data)))}\n"
   ],
   "metadata": {
    "id": "EWRJbOscRCsd",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.795188Z",
     "start_time": "2024-05-22T08:05:30.779557Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "Kn0BdGWO7mhO",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.810191Z",
     "start_time": "2024-05-22T08:05:30.795188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def peptide2vec(peptides):\n",
    "    t = torch.zeros(len(peptides),len(amino_to_ind) * len(peptides[0]))\n",
    "    for j,peptide in enumerate(peptides):\n",
    "        for i,amino in enumerate(peptide):\n",
    "            t[j, i*len(amino_to_ind) +amino_to_ind[amino]] = 1\n",
    "    return t"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "id": "z_kvFe277mhO",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.825890Z",
     "start_time": "2024-05-22T08:05:30.811676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print(peptide2vec(load_raw()[1]))\n",
    "# t = peptide2vec(load_raw()[0][:10])\n",
    "# px.imshow(t)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "ycMc9anC7mhO",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.844428Z",
     "start_time": "2024-05-22T08:05:30.827888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_vec_data(raw_neg_data , raw_pos_data):\n",
    "    neg_data = peptide2vec(raw_neg_data)\n",
    "    pos_data = peptide2vec(raw_pos_data)\n",
    "    return neg_data, pos_data\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "svIllr187mhO",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.874957Z",
     "start_time": "2024-05-22T08:05:30.844428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_train_test(neg_data, pos_data,ratio=0.9):\n",
    "    shuffle_pos = torch.randperm(len(pos_data))\n",
    "    num_train_pos = int(ratio*len(pos_data))\n",
    "    idx_train_pos = shuffle_pos[num_train_pos:]\n",
    "    idx_test_pos = shuffle_pos[:num_train_pos]\n",
    "\n",
    "    shuffle_neg = torch.randperm(len(neg_data))\n",
    "    num_train_neg = int(ratio*len(neg_data))\n",
    "    idx_train_neg = shuffle_neg[num_train_neg:]\n",
    "    idx_test_neg = shuffle_neg[:num_train_neg]\n",
    "\n",
    "    return pos_data[idx_train_pos],pos_data[idx_test_pos], neg_data[idx_train_neg], neg_data[idx_test_neg]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "iYYIYFO97mhP",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.890763Z",
     "start_time": "2024-05-22T08:05:30.876955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "def make_data_set(pos_train, pos_test, neg_train, neg_test):\n",
    "    train_data = torch.cat((pos_train, neg_train))\n",
    "    train_labels = torch.cat((torch.ones(len(pos_train)), torch.zeros(len(neg_train))))\n",
    "    train_data_set = TensorDataset(train_data, train_labels)\n",
    "\n",
    "    test_data = torch.cat((pos_test, neg_test))\n",
    "    test_labels = torch.cat((torch.ones(len(pos_test)), torch.zeros(len(neg_test))))\n",
    "\n",
    "    class_count = torch.bincount(train_labels.to(int))\n",
    "    class_weights = 1. / class_count.float()\n",
    "    sample_weights = class_weights[train_labels.to(int)]\n",
    "    train_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    return train_data_set, train_sampler, test_data, test_labels\n",
    "\n",
    "# todo: use BCEWithLogitsLoss whith pos_weight to balance the classes\n",
    "\n",
    "# todo: another option: use a dataloader, put the pos len(neg/pos) times in the dataset.\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def make_unbiased_data_loader(train_data_set, test_data, test_labels,batch_size=16,sampler=None):\n",
    "    train_loader = DataLoader(train_data_set, batch_size=batch_size,sampler=sampler)\n",
    "    # train_loader = DataLoader(train_data_set, batch_size=batch_size)\n",
    "    return train_loader, test_data, test_labels"
   ],
   "metadata": {
    "id": "ZOvr4zi0Aznw",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.911031Z",
     "start_time": "2024-05-22T08:05:30.892377Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "id": "Hzbx0z-p7mhP",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.926654Z",
     "start_time": "2024-05-22T08:05:30.911031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP_multi_perceptron(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_multi_perceptron, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = self.sigmoid(out) todo: loss function is BCEWithLogits \n",
    "        return out\n",
    "    def predict(self,x,threshold=0.5):\n",
    "        # return (self.forward(x)>threshold).to(float) todo: loss function is BCE\n",
    "        return (self.sigmoid(self.forward(x))>threshold).to(float)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "id": "9J7XkuQK7mhP",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.942280Z",
     "start_time": "2024-05-22T08:05:30.926654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, test_data, test_labels, loss_fn, optimizer, epochs,device):\n",
    "    test_data, test_labels = test_data.to(device), test_labels.to(device)\n",
    "    records = pd.DataFrame(columns=['epoch', 'train_loss', 'test_loss'],index=range(epochs))\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            cur_loss = loss_fn(model(x).flatten(), y)\n",
    "            train_epoch_loss += cur_loss.item()\n",
    "            cur_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # prod = model.predict(test_data.to(device),threshold=0.99)\n",
    "            prod = model.predict(test_data.to(device))\n",
    "            accuracy = torch.mean((prod == test_labels).to(float)).item()\n",
    "            false_pos = torch.mean(((prod == 1) & (test_labels == 0)).to(float)).item()\n",
    "            true_pos = torch.mean(((prod == 1) & (test_labels == 1)).to(float)).item()\n",
    "            false_neg = torch.mean(((prod == 0) & (test_labels == 1)).to(float)).item()\n",
    "            true_neg = torch.mean(((prod == 0) & (test_labels == 0)).to(float)).item()\n",
    "            print(f'epoch:{epoch} - accuracy: {accuracy*100:.2f}%, Precision: {(true_pos/(max(true_pos+false_pos,1e-10)))*100:.2f}:%, Recall {(true_pos/max(true_pos+false_neg,1e-10))*100:.2f}%')\n",
    "            # print(f'epoch:{epoch} - accuracy: {accuracy*100:.2f}%, false positive: {false_pos*100:.2f}:%, false negative {false_neg*100:.2f}%')\n",
    "            test_loss = loss_fn(model(test_data).flatten(), test_labels).item()\n",
    "        records.iloc[epoch] = [epoch, train_epoch_loss, test_loss]\n",
    "    return  records"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "id": "Jp18oa0Q7mhP",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:30.959801Z",
     "start_time": "2024-05-22T08:05:30.944789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "HIDDEN_SIZE = 7\n",
    "INPUT_SIZE = len(amino_to_ind) * 9\n",
    "OUTPUT_SIZE = 1"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "raw_neg_data, raw_pos_data = load_raw('ex1_data/')\n",
    "# raw_neg_data, raw_pos_data = load_raw()\n",
    "neg_data, pos_data = load_vec_data(raw_neg_data, raw_pos_data)\n",
    "pos_train, pos_test, neg_train, neg_test = split_train_test(neg_data, pos_data)\n",
    "train_data_set, sampler, test_data, test_labels = make_data_set(pos_train, pos_test, neg_train, neg_test)\n",
    "train_loader, test_data, test_labels = make_unbiased_data_loader(train_data_set, test_data, test_labels,BATCH_SIZE)"
   ],
   "metadata": {
    "id": "ufGBWSCiDpc4",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:32.062338Z",
     "start_time": "2024-05-22T08:05:30.961799Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "id": "4oOX3BfL7mhP",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:05:33.543044Z",
     "start_time": "2024-05-22T08:05:32.062338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = MLP_multi_perceptron(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
    "# loss_fn = torch.nn.BCELoss()\n",
    "LOSS_WHIGHT = torch.tensor([len(neg_train)/len(pos_train)]).to(DEVICE)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=LOSS_WHIGHT)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "o7igfN657mhP",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:08:21.328807Z",
     "start_time": "2024-05-22T08:05:33.543044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "record_data = train_model(model,train_loader,test_data,test_labels,loss_fn,optimizer,EPOCHS,DEVICE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - accuracy: 34.22%, Precision: 10.88:%, Recall 70.18%\n",
      "epoch:1 - accuracy: 79.13%, Precision: 10.88:%, Recall 12.77%\n",
      "epoch:2 - accuracy: 76.32%, Precision: 10.88:%, Recall 16.36%\n",
      "epoch:3 - accuracy: 76.35%, Precision: 10.88:%, Recall 16.31%\n",
      "epoch:4 - accuracy: 75.39%, Precision: 10.88:%, Recall 17.55%\n",
      "epoch:5 - accuracy: 74.96%, Precision: 10.88:%, Recall 18.10%\n",
      "epoch:6 - accuracy: 74.28%, Precision: 10.88:%, Recall 18.96%\n",
      "epoch:7 - accuracy: 74.18%, Precision: 10.88:%, Recall 19.09%\n",
      "epoch:8 - accuracy: 73.65%, Precision: 10.88:%, Recall 19.77%\n",
      "epoch:9 - accuracy: 73.73%, Precision: 10.88:%, Recall 19.67%\n",
      "epoch:10 - accuracy: 73.33%, Precision: 10.88:%, Recall 20.17%\n",
      "epoch:11 - accuracy: 73.32%, Precision: 10.88:%, Recall 20.20%\n",
      "epoch:12 - accuracy: 73.24%, Precision: 10.88:%, Recall 20.29%\n",
      "epoch:13 - accuracy: 73.32%, Precision: 10.88:%, Recall 20.19%\n",
      "epoch:14 - accuracy: 73.22%, Precision: 10.88:%, Recall 20.32%\n",
      "epoch:15 - accuracy: 73.43%, Precision: 10.88:%, Recall 20.05%\n",
      "epoch:16 - accuracy: 73.26%, Precision: 10.88:%, Recall 20.26%\n",
      "epoch:17 - accuracy: 73.56%, Precision: 10.88:%, Recall 19.89%\n",
      "epoch:18 - accuracy: 73.43%, Precision: 10.88:%, Recall 20.05%\n",
      "epoch:19 - accuracy: 73.61%, Precision: 10.88:%, Recall 19.83%\n",
      "epoch:20 - accuracy: 73.60%, Precision: 10.88:%, Recall 19.83%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m record_data \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[11], line 21\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, test_data, test_labels, loss_fn, optimizer, epochs, device)\u001B[0m\n\u001B[0;32m     19\u001B[0m false_pos \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(((prod \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m&\u001B[39m (test_labels \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m))\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mfloat\u001B[39m))\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     20\u001B[0m true_pos \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(((prod \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m&\u001B[39m (test_labels \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mfloat\u001B[39m))\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m---> 21\u001B[0m false_neg \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprod\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_labels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     22\u001B[0m true_neg \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(((prod \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m&\u001B[39m (test_labels \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m))\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mfloat\u001B[39m))\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%, Precision: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(true_pos\u001B[38;5;241m/\u001B[39m(\u001B[38;5;28mmax\u001B[39m(true_pos\u001B[38;5;241m+\u001B[39mfalse_pos,\u001B[38;5;241m1e-10\u001B[39m)))\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:%, Recall \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(true_pos\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mmax\u001B[39m(true_pos\u001B[38;5;241m+\u001B[39mfalse_neg,\u001B[38;5;241m1e-10\u001B[39m))\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "id": "4FbUICNP7mhQ"
   },
   "cell_type": "code",
   "source": [
    "px.line(record_data,x='epoch',y=['train_loss','test_loss'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# hyper parameters\n",
    "1. batch: 32, epochs: ->∞ , hidden: 25, score: 80"
   ],
   "metadata": {
    "id": "tFaC5v0nIg3J"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "wMNMIrMyZL6s",
    "ExecuteTime": {
     "end_time": "2024-05-22T08:08:21.330843Z",
     "start_time": "2024-05-22T08:08:21.330843Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "JPPj0Nwp7mhQ"
   },
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Sample data (replace with your actual model output and labels)\n",
    "pred = model(test_data.to('cuda')).detach().cpu().numpy()\n",
    "true_labels = test_labels.detach().cpu().numpy()\n",
    "# Calculate ROC curve data\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, pred)\n",
    "roc_auc = auc(fpr, tpr)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Create the Plotly figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fpr, y=tpr,\n",
    "                         mode='lines',\n",
    "                         line=dict(color='darkorange', width=2),\n",
    "                         name=f'ROC curve (area = {roc_auc:.2f})'))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1],\n",
    "                         mode='lines',\n",
    "                         line=dict(color='navy', width=2, dash='dash'),\n",
    "                         showlegend=False))\n",
    "fig.update_layout(\n",
    "    title='Receiver Operating Characteristic (ROC) Curve',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    xaxis=dict(range=[0, 1]),\n",
    "    yaxis=dict(range=[0, 1.05]),\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "id": "yHl8Jq5jX_LY"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "hqjVo1aiZsCZ"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
